{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We'll use tensorflow to predict the number of shapes in each image.\n",
    "\n",
    "First let's get the pixel data, saving it as `.npy` files in `greyscale-data`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import png\n",
    "\n",
    "\n",
    "input_directory = 'greyscaled-images'\n",
    "output_directory = 'greyscaled-data'\n",
    "if not os.path.exists(output_directory):\n",
    "  os.makedirs(output_directory)\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "  path = os.path.join(input_directory, filename)\n",
    "  with open(path, 'rb') as image_file:\n",
    "    reader = png.Reader(file=image_file)\n",
    "    _, _, pixels, _ = reader.asDirect()\n",
    "    data = np.array([x / 255. for row in pixels for x in row])\n",
    "  output_filename = '%s.npy' % filename.split('.')[0]\n",
    "  output_path = os.path.join(output_directory, output_filename)\n",
    "  np.save(output_path, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Load data into various structures for later.  This cell mainly splits the data into training, validation and test folds.  To make the splits I'm hashing filenames and then sorting those hashes alphabetically -- this mixes up the images, but makes the mixing deterministic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "input_directory = 'greyscaled-data'\n",
    "\n",
    "# Load all the data into an array.\n",
    "# Each element is a tuple: (filename, numpy data).\n",
    "# The filename structure is \"<number>-<color>-<texture>-<shape>-<rotation>.png\"\n",
    "all_data = [\n",
    "  (f, np.load(os.path.join(input_directory, f))) for f in os.listdir(input_directory)\n",
    "]\n",
    "\n",
    "# Hash the filename and sort the hashes alphabetically.\n",
    "all_data_with_hashes = [\n",
    "  (filename, hashlib.md5(filename).hexdigest(), data) for filename, data in all_data\n",
    "]\n",
    "all_data_sorted = sorted(all_data_with_hashes, key=lambda element: element[1])\n",
    "\n",
    "# Save 20% of the data for testing (the final, one-shot evaluation of performance).\n",
    "split_index = int(0.2 * len(all_data_sorted))\n",
    "test_data = all_data_sorted[0:split_index]\n",
    "remaining_data = all_data_sorted[split_index:]\n",
    "\n",
    "# Now save 20% of the remaining data for validation.\n",
    "split_index = int(0.2 * len(remaining_data))\n",
    "validation_data = remaining_data[0:split_index]\n",
    "training_data = remaining_data[split_index:]\n",
    "\n",
    "# For convenience, get all the pixel data into separate arrays.\n",
    "training_pixel_data = [pixel_data for _, _, pixel_data in training_data]\n",
    "validation_pixel_data = np.array([pixel_data for _, _, pixel_data in validation_data])\n",
    "test_pixel_data = np.array([pixel_data for _, _, pixel_data in test_data])\n",
    "\n",
    "# Each filename, in its text, has an embedded \"number of shapes.\"\n",
    "# We need to convert those classes (the output ground truth) into label arrays.\n",
    "all_labels = [\n",
    "    [1., 0., 0.],\n",
    "    [0., 1., 0.],\n",
    "    [0., 0., 1.],\n",
    "]\n",
    "training_labels = [\n",
    "  all_labels[int(filename.split('-')[0]) - 1] for filename, _, _ in training_data\n",
    "]\n",
    "validation_labels = [\n",
    "  all_labels[int(filename.split('-')[0]) - 1] for filename, _, _ in validation_data\n",
    "]\n",
    "test_labels = [\n",
    "  all_labels[int(filename.split('-')[0]) - 1] for filename, _, _ in test_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "setup tensorflow\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "learning_rate = 0.5\n",
    "regularization_factor = 1e-4\n",
    "card_width, card_height = 150, 150\n",
    "hidden_layer_size = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Setup the training steps.\n",
    "  tf_training_data = tf.placeholder(tf.float32, shape=[None, card_width*card_height])\n",
    "  tf_training_labels = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "  \n",
    "  # Create a single hidden layer of ReLUs.\n",
    "  hidden_weights = tf.Variable(tf.zeros([card_width*card_height, hidden_layer_size]))\n",
    "  hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "  hidden_layer = tf.nn.relu(tf.matmul(tf_training_data, hidden_weights) + hidden_biases)\n",
    "  \n",
    "  # Build the output layer.\n",
    "  output_weights = tf.Variable(tf.zeros([hidden_layer_size, 3]))\n",
    "  output_biases = tf.Variable(tf.zeros([3]))\n",
    "  output_logits = tf.matmul(hidden_layer, output_weights) + output_biases\n",
    "  training_estimate = tf.nn.softmax(output_logits)\n",
    "\n",
    "  # Calculate loss and setup the optimizer.\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_logits, tf_training_labels))\n",
    "  l2_regularization = tf.nn.l2_loss(output_weights) + tf.nn.l2_loss(hidden_weights)\n",
    "  loss += regularization_factor * l2_regularization\n",
    "  training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "  # Setup validation.  We have to reshape into a \"dense tensor\"\n",
    "  # by, essentially, combining this array of arrays into a true matrix.\n",
    "  tf_validation_pixel_data = tf.constant(\n",
    "    validation_pixel_data.reshape((-1, card_width*card_height)).astype(np.float32))\n",
    "  validation_hidden_layer = tf.nn.relu(tf.matmul(tf_validation_pixel_data, hidden_weights) + hidden_biases)\n",
    "  validation_logits = tf.matmul(validation_hidden_layer, output_weights) + output_biases\n",
    "  validation_estimate = tf.nn.softmax(validation_logits)\n",
    "\n",
    "  # Setup the final test run.\n",
    "  tf_test_pixel_data = tf.constant(\n",
    "    test_pixel_data.reshape((-1, card_width*card_height)).astype(np.float32))\n",
    "  test_hidden_layer = tf.nn.relu(tf.matmul(tf_test_pixel_data, hidden_weights) + hidden_biases)\n",
    "  test_logits = tf.matmul(test_hidden_layer, output_weights) + output_biases\n",
    "  test_estimate = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "aside: create a small function to calculate the accuracy of a set of predictions\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, ground_truth):\n",
    "  \"\"\"Determine what proportion of predictions are accurate based on ground truth.\"\"\"\n",
    "  correctness = np.sum(np.argmax(predictions, 1) == np.argmax(ground_truth, 1))\n",
    "  return 100. * correctness / predictions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "and run the optimizer in batches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 -> training accuracy: 38.0%, validation accuracy: 32.0%\n",
      "iteration: 20 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 40 -> training accuracy: 27.0%, validation accuracy: 33.0%\n",
      "iteration: 60 -> training accuracy: 28.0%, validation accuracy: 35.0%\n",
      "iteration: 80 -> training accuracy: 34.0%, validation accuracy: 35.0%\n",
      "iteration: 100 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 120 -> training accuracy: 34.0%, validation accuracy: 32.0%\n",
      "iteration: 140 -> training accuracy: 39.0%, validation accuracy: 33.0%\n",
      "iteration: 160 -> training accuracy: 32.0%, validation accuracy: 32.0%\n",
      "iteration: 180 -> training accuracy: 32.0%, validation accuracy: 32.0%\n",
      "iteration: 200 -> training accuracy: 34.0%, validation accuracy: 35.0%\n",
      "iteration: 220 -> training accuracy: 33.0%, validation accuracy: 33.0%\n",
      "iteration: 240 -> training accuracy: 35.0%, validation accuracy: 35.0%\n",
      "iteration: 260 -> training accuracy: 26.0%, validation accuracy: 33.0%\n",
      "iteration: 280 -> training accuracy: 36.0%, validation accuracy: 35.0%\n",
      "iteration: 300 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 320 -> training accuracy: 33.0%, validation accuracy: 33.0%\n",
      "iteration: 340 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 360 -> training accuracy: 42.0%, validation accuracy: 35.0%\n",
      "iteration: 380 -> training accuracy: 27.0%, validation accuracy: 32.0%\n",
      "iteration: 400 -> training accuracy: 38.0%, validation accuracy: 33.0%\n",
      "iteration: 420 -> training accuracy: 35.0%, validation accuracy: 35.0%\n",
      "iteration: 440 -> training accuracy: 31.0%, validation accuracy: 33.0%\n",
      "iteration: 460 -> training accuracy: 29.0%, validation accuracy: 33.0%\n",
      "iteration: 480 -> training accuracy: 36.0%, validation accuracy: 35.0%\n",
      "iteration: 500 -> training accuracy: 30.0%, validation accuracy: 33.0%\n",
      "iteration: 520 -> training accuracy: 38.0%, validation accuracy: 33.0%\n",
      "iteration: 540 -> training accuracy: 35.0%, validation accuracy: 33.0%\n",
      "iteration: 560 -> training accuracy: 31.0%, validation accuracy: 32.0%\n",
      "iteration: 580 -> training accuracy: 30.0%, validation accuracy: 35.0%\n",
      "iteration: 600 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 620 -> training accuracy: 34.0%, validation accuracy: 32.0%\n",
      "iteration: 640 -> training accuracy: 31.0%, validation accuracy: 33.0%\n",
      "iteration: 660 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 680 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 700 -> training accuracy: 31.0%, validation accuracy: 35.0%\n",
      "iteration: 720 -> training accuracy: 29.0%, validation accuracy: 33.0%\n",
      "iteration: 740 -> training accuracy: 30.0%, validation accuracy: 35.0%\n",
      "iteration: 760 -> training accuracy: 33.0%, validation accuracy: 35.0%\n",
      "iteration: 780 -> training accuracy: 34.0%, validation accuracy: 35.0%\n",
      "iteration: 800 -> training accuracy: 36.0%, validation accuracy: 35.0%\n",
      "iteration: 820 -> training accuracy: 33.0%, validation accuracy: 33.0%\n",
      "iteration: 840 -> training accuracy: 31.0%, validation accuracy: 32.0%\n",
      "iteration: 860 -> training accuracy: 37.0%, validation accuracy: 35.0%\n",
      "iteration: 880 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 900 -> training accuracy: 32.0%, validation accuracy: 33.0%\n",
      "iteration: 920 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 940 -> training accuracy: 39.0%, validation accuracy: 33.0%\n",
      "iteration: 960 -> training accuracy: 28.0%, validation accuracy: 33.0%\n",
      "iteration: 980 -> training accuracy: 24.0%, validation accuracy: 33.0%\n",
      "iteration: 1000 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 1020 -> training accuracy: 38.0%, validation accuracy: 35.0%\n",
      "iteration: 1040 -> training accuracy: 31.0%, validation accuracy: 33.0%\n",
      "iteration: 1060 -> training accuracy: 37.0%, validation accuracy: 33.0%\n",
      "iteration: 1080 -> training accuracy: 33.0%, validation accuracy: 33.0%\n",
      "iteration: 1100 -> training accuracy: 36.0%, validation accuracy: 33.0%\n",
      "iteration: 1120 -> training accuracy: 29.0%, validation accuracy: 35.0%\n",
      "iteration: 1140 -> training accuracy: 38.0%, validation accuracy: 33.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-95931e672784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     _, _, training_predictions = session.run(\n\u001b[1;32m---> 20\u001b[1;33m       [training_step, loss, training_estimate], feed_dict=batch_training_data)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_iterations\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "total_iterations = 1000\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  for iteration in range(total_iterations):\n",
    "    batch_data = random.sample(training_data, batch_size)\n",
    "    batch_input_pixel_data = [pixel_data for _, _, pixel_data in batch_data]\n",
    "    batch_labels = [\n",
    "      all_labels[int(filename.split('-')[0]) - 1] for filename, _, _ in batch_data\n",
    "    ]\n",
    "    batch_training_data = {\n",
    "      tf_training_data: batch_input_pixel_data,\n",
    "      tf_training_labels: batch_labels,\n",
    "    }\n",
    "  \n",
    "    _, _, training_predictions = session.run(\n",
    "      [training_step, loss, training_estimate], feed_dict=batch_training_data)\n",
    "  \n",
    "    if (iteration % (total_iterations / 100)) == 0:\n",
    "      training_accuracy = calculate_accuracy(training_predictions, batch_labels)\n",
    "      validation_accuracy = calculate_accuracy(validation_estimate.eval(), validation_labels)\n",
    "      accuracies.append((iteration, training_accuracy, validation_accuracy))\n",
    "      if (iteration % (total_iterations / 50)) == 0:\n",
    "        print 'iteration: %s -> training accuracy: %0.1f%%, validation accuracy: %0.1f%%' % (\n",
    "          iteration, training_accuracy, validation_accuracy)\n",
    "  print '\\ntest accuracy: %0.1f%%' % calculate_accuracy(test_estimate.eval(), test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "plot the accuracy vs iteration number\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "iterations, training_accuracies, validation_accuracies = zip(*accuracies)\n",
    "plt.plot(iterations, training_accuracies, 'r-', label='training')\n",
    "plt.plot(iterations, validation_accuracies, 'g-', label='validation')\n",
    "_ = plt.xlabel('iteration')\n",
    "_ = plt.ylabel('validation accuracy')\n",
    "_ = plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
