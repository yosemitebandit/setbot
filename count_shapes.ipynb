{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We'll use tensorflow to predict the number of shapes in each image.\n",
    "\n",
    "First let's get the pixel data, saving it as `.npy` files in `greyscale-data`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import png\n",
    "\n",
    "\n",
    "input_directory = 'greyscaled-images'\n",
    "output_directory = 'greyscaled-data'\n",
    "if not os.path.exists(output_directory):\n",
    "  os.makedirs(output_directory)\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "  path = os.path.join(input_directory, filename)\n",
    "  with open(path, 'rb') as image_file:\n",
    "    reader = png.Reader(file=image_file)\n",
    "    _, _, pixels, _ = reader.asDirect()\n",
    "    data = np.array([x / 255. for row in pixels for x in row])\n",
    "  output_filename = '%s.npy' % filename.split('.')[0]\n",
    "  output_path = os.path.join(output_directory, output_filename)\n",
    "  np.save(output_path, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Load data into various structures for later.  This cell mainly splits the data into training, validation and test folds.  To make the splits I'm hashing filenames and then sorting those hashes alphabetically -- this mixes up the images, but makes the mixing deterministic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "input_directory = 'greyscaled-data'\n",
    "\n",
    "# Load all the data into an array.\n",
    "# Each element is a tuple: (filename, numpy data).\n",
    "# The filename structure is \"<number>-<color>-<texture>-<shape>-<rotation>.png\"\n",
    "all_data = [\n",
    "  (f, np.load(os.path.join(input_directory, f))) for f in os.listdir(input_directory)\n",
    "]\n",
    "\n",
    "# Hash the filename and sort the hashes alphabetically.\n",
    "all_data_with_hashes = [\n",
    "  (filename, hashlib.md5(filename).hexdigest(), data) for filename, data in all_data\n",
    "]\n",
    "all_data_sorted = sorted(all_data_with_hashes, key=lambda element: element[1])\n",
    "\n",
    "# Save 20% of the data for testing (the final, one-shot evaluation of performance).\n",
    "split_index = int(0.2 * len(all_data_sorted))\n",
    "test_data = all_data_sorted[0:split_index]\n",
    "remaining_data = all_data_sorted[split_index:]\n",
    "\n",
    "# Now save 20% of the remaining data for validation.\n",
    "split_index = int(0.2 * len(remaining_data))\n",
    "validation_data = remaining_data[0:split_index]\n",
    "training_data = remaining_data[split_index:]\n",
    "\n",
    "# For convenience, get all the pixel data into separate arrays.\n",
    "training_pixel_data = [pixel_data for _, _, pixel_data in training_data]\n",
    "validation_pixel_data = np.array([pixel_data for _, _, pixel_data in validation_data])\n",
    "test_pixel_data = np.array([pixel_data for _, _, pixel_data in test_data])\n",
    "\n",
    "# Each filename, in its text, has an embedded \"number of shapes.\"\n",
    "# We need to convert those classes (the output ground truth) into category arrays.\n",
    "possible_categories = [\n",
    "    [1., 0., 0.],\n",
    "    [0., 1., 0.],\n",
    "    [0., 0., 1.],\n",
    "]\n",
    "training_output_categories = [\n",
    "  possible_categories[int(filename.split('-')[0]) - 1] for filename, _, _ in training_data\n",
    "]\n",
    "validation_output_categories = [\n",
    "  possible_categories[int(filename.split('-')[0]) - 1] for filename, _, _ in validation_data\n",
    "]\n",
    "test_output_categories = [\n",
    "  possible_categories[int(filename.split('-')[0]) - 1] for filename, _, _ in test_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "setup tensorflow\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorrect_prediction = tf.equal(\\n  tf.argmax(estimated_output_category, 1), \\n  tf.argmax(actual_output_category, 1))\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "learning_rate = 1e-6\n",
    "card_width, card_height = 150, 150\n",
    "\n",
    "# Setup the training steps.\n",
    "tf_training_data = tf.placeholder(tf.float32, shape=[None, card_width*card_height])\n",
    "tf_training_labels = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "#input_pixel_data = tf.placeholder(tf.float32, shape=[None, card_width*card_height])\n",
    "weights = tf.Variable(tf.zeros([card_width*card_height, 3]))\n",
    "biases = tf.Variable(tf.zeros([3]))\n",
    "estimated_output_category_in_training = tf.nn.softmax(tf.matmul(tf_training_data, weights) + biases)\n",
    "#actual_output_category = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(tf_training_labels * tf.log(estimated_output_category_in_training))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, ground_truth):\n",
    "  \"\"\"Determine what proportion of predictions are accurate based on ground truth.\"\"\"\n",
    "  correctness = tf.equal(tf.argmax(predictions, 1), tf.argmax(ground_truth, 1))\n",
    "  return tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "\n",
    "\n",
    "# Setup validation.  We have to reshape to a \"dense tensor\"\n",
    "# by, essentially, combining this array of arrays into a true matrix.\n",
    "tf_validation_pixel_data = tf.constant(\n",
    "  validation_pixel_data.reshape((-1, card_width*card_height)).astype(np.float32))\n",
    "estimated_output_category_in_validation = tf.nn.softmax(tf.matmul(tf_validation_pixel_data, weights) + biases)\n",
    "validation_accuracy = calculate_accuracy(estimated_output_category_in_validation, validation_output_categories)\n",
    "\n",
    "# Setup the final test run.\n",
    "tf_test_data = tf.constant(\n",
    "  test_pixel_data.reshape((-1, card_width*card_height)).astype(np.float32))\n",
    "\n",
    "'''\n",
    "correct_prediction = tf.equal(\n",
    "  tf.argmax(estimated_output_category, 1), \n",
    "  tf.argmax(actual_output_category, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "and run the optimizer in batches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/matt/conf/venvs/setbot/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-95ad47ecd1ae>\", line 8, in <module>\n    input_pixel_data = tf.placeholder(tf.float32, shape=[None, card_width*card_height])\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 742, in placeholder\n    name=name)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 583, in _placeholder\n    name=name)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-727d95c62372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m       \u001b[0mtf_training_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalidation_output_categories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     }\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_input_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mvalidation_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 586\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/matt/conf/venvs/setbot/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-95ad47ecd1ae>\", line 8, in <module>\n    input_pixel_data = tf.placeholder(tf.float32, shape=[None, card_width*card_height])\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 742, in placeholder\n    name=name)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 583, in _placeholder\n    name=name)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/matt/conf/venvs/setbot/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "validation_accuracies = []\n",
    "total_iterations = 1000\n",
    "batch_size = 100\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.initialize_all_variables())\n",
    "\n",
    "for iteration in range(total_iterations):\n",
    "  batch_data = random.sample(training_data, batch_size)\n",
    "  batch_input_pixel_data = [pixel_data for _, _, pixel_data in batch_data]\n",
    "  batch_output_categories = [\n",
    "    possible_categories[int(filename.split('-')[0]) - 1] for filename, _, _ in batch_data\n",
    "  ]\n",
    "  batch_training_data = {\n",
    "    tf_training_data: batch_input_pixel_data,\n",
    "    tf_training_labels: batch_output_categories,\n",
    "  }\n",
    "  \n",
    "  session.run(training_step, feed_dict=batch_training_data)\n",
    "  \n",
    "  if (iteration % 50) == 0:\n",
    "    validation_input_data = {\n",
    "      tf_training_data: validation_pixel_data,\n",
    "      tf_training_labels: validation_output_categories,\n",
    "    }\n",
    "    accuracy = session.run(accuracy, feed_dict=validation_input_data)\n",
    "    validation_accuracies.append((iteration, accuracy))\n",
    "    if (iteration % 100) == 0:\n",
    "      print 'iteration: %s -> accuracy: %s' % (iteration, measured_accuracy)\n",
    "\n",
    "print 'done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "plot the accuracy vs iteration number\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f346a76bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(measured_iterations, measured_accuracies, 'bo')\n",
    "plt.plot(measured_iterations, measured_accuracies, 'k-')\n",
    "_ = plt.xlabel('iteration')\n",
    "_ = plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
